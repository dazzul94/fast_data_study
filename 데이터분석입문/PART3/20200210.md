ㅇ신경망 모델(Neural Networks), 딥러닝(Deep learning)

1. 신경망 모델(Neural Networks)
: 머신러닝 기법 중 하나의 부류로,
기술의 발전과 많은 연구에 힘입어 가장 널리 쓰이고 있는 방법
-> 뉴런과 뉴런 사이에 시냅스(노드)
ex) Feed-forward Network
- Input layer, Hidden layer, Output layer
- In a node: 가중치(weight를 곱한 값들을 더한다.)
-> 추론은 정방형으로 , 학습은 역방향으로! 역전파(Backpropagation)방법으로 학습이 일어남

2. 딥러닝(Deep learning)
- 인공신경망이 더 발전된 형태
- 데이터 표현을 직접 학습하여 높은 수준의 추상화를 시도하는 머신러닝 알고리즘의 집합

-> 히든 레이어 첫번째 은닉층에서는 저수준의 추상화, 갈수록 고수준의 추상화로 학습한다.

* 딥러닝 < 머신러닝 < 인공지능
ex) Convolution neural networks, Recurrent neural networks, Generative adversarial networks

- ImageNet Large Scale Visual Recognition Challenge(ILSVRC)
이미지 분류 부분(AlexNet, ZFNet, VGGNet, GoogLeNet, ResNet, DenseNet)
- Object Detection -> 사물이 있는 곳을 찾고 그 사물이 뭔지?
- Neural Machine Translation: 인공신경망 번역
- Image Caption Generation
- 음성인식, 이미지 합성, Super-resolution imaging, Language model, Question answering model

ㅇ파라미터(Parameter)와 하이퍼파라미터(Hyper parameter)
1. 파라미터
- 모델의 구성 요소이자 데이터로부터 학습되는 것
- 선형 회귀 모델에서 목적은 y = ax+b를 학습하는것이다.
학습을 통해서 y = -x + 10을 찾아냈다고 하자. 현재 데이터를 가장 잘 설명하는 직선
이때 파라미터 a,b가 파라미터이다.
- 신경망(Feed-forward Network)에서 학습해야 하는 것은 weight 이것이 학습을 통해서 찾아가야 하는 값
가중치가 파라미터이다.

2. 하이퍼 파라미터
- 모델학습 과정에 반영되며, 학습을 시작하기 전에 미리 값을 결정하는 것
- 여러 오븐에 각각 다른 세팅을 주어 빵을 구우면? (160도,20분/180도,18분/200도,16분)
결과가 다르다 . 180도에 18분을 구웠을 때 빵이 잘 익는다. 이 온도와 시간이 하이퍼파라미터이다.
- 좋은 모델을 만들기 위해서는 하이퍼파라미터를 잘 튜닝/컨트롤해야 한다.
- 신경망 모델에서의 은닉 노드 수나 은닉층을 추가하는 일이 하이퍼파라미터를 튜닝하는 것이다.